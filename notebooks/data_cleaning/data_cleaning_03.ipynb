{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPohWEEb0BG7jQLg3CPpGCO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niranjana-08/AI-Ascent/blob/main/notebooks/data_cleaning/data_cleaning_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "paragraph comparing"
      ],
      "metadata": {
        "id": "NhzA00lcfqs3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook Overview :  \n",
        "\n",
        "\n",
        "*   This notebook classifies job descriptions into sub-categories using Sentence Transformer embeddings based on semantic similarity.\n",
        "*   It loads a cleaned dataset and a hierarchical keyword list, encoding keyword paragraphs into vectors.\n",
        "*   Job descriptions are then encoded and compared to keyword embeddings using cosine similarity.\n",
        "*   Each job is assigned the category with the highest similarity score, along with a confidence measure. The process leverages GPU acceleration for efficient computation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w57UvRu0tu8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. running on T4 GPU\n",
        "2. Using keywords-mega\n",
        "3. sentence transformer usage"
      ],
      "metadata": {
        "id": "dn6-8a8JtDwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup & Imports"
      ],
      "metadata": {
        "id": "oLHAfG0BMs5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers -q"
      ],
      "metadata": {
        "id": "2UFWivXJuxs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "from google.colab import drive\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from tqdm.auto import tqdm\n",
        "import torch"
      ],
      "metadata": {
        "id": "XG3wH-dzu3rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Loading"
      ],
      "metadata": {
        "id": "DFS9LkxoM2Nw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive and load dataset files for processing."
      ],
      "metadata": {
        "id": "I4kA9YVrM4Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mounting Google Drive\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "keywords_folder_path = '/content/drive/My Drive/job-analysis/job-analysis-dataset/keywords/'\n",
        "sys.path.append(keywords_folder_path)\n",
        "data_file_path = '/content/drive/My Drive/job-analysis/job-analysis-dataset/data_cleaning/cleaned_for_classification.csv'"
      ],
      "metadata": {
        "id": "knUdU7Si5fQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load project-specific keywords and the cleaned classification dataset."
      ],
      "metadata": {
        "id": "QPZYWem0NANK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from keywords_mega_changed import MEGA_KEYWORDS\n",
        "    df = pd.read_csv(data_file_path)\n",
        "except (ImportError, FileNotFoundError) as e:\n",
        "    print(f\"Error: Could not load files. Details: {e}\")\n",
        "    raise e"
      ],
      "metadata": {
        "id": "L8u0iTsh5jbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Prepare List of Sub-Categories and Keyword Paragraphs"
      ],
      "metadata": {
        "id": "pdY9VSwFNJ5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten nested keywords structure to lists and create mapping from sub-category to main category."
      ],
      "metadata": {
        "id": "7ob4b7doNKRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_sub_categories = []\n",
        "mega_keyword_paragraphs = []\n",
        "sub_to_main_map = {}\n",
        "for main_cat, sub_cats in MEGA_KEYWORDS.items():\n",
        "    for sub_cat_name, paragraph in sub_cats.items():\n",
        "        all_sub_categories.append(sub_cat_name)\n",
        "        mega_keyword_paragraphs.append(paragraph)\n",
        "        sub_to_main_map[sub_cat_name] = main_cat\n",
        "print(f\"\\nCreated a flat list of {len(all_sub_categories)} sub-categories.\")"
      ],
      "metadata": {
        "id": "cpZWATXE60Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Load Model and Encode Keyword Paragraphs"
      ],
      "metadata": {
        "id": "fG4_KAXINYzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the pre-trained Sentence Transformer model and verify GPU availability."
      ],
      "metadata": {
        "id": "WjKXrSfxNb6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
        "\n",
        "print(\"Encoding sub-category keywords into vectors...\")\n",
        "category_embeddings = model.encode(mega_keyword_paragraphs, convert_to_tensor=True, show_progress_bar=True)\n"
      ],
      "metadata": {
        "id": "nXd86Zu862Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Initial Classification on Sample Dataset"
      ],
      "metadata": {
        "id": "Xz1VfP0WNpcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode a sample of job descriptions and calculate similarity scores to assign initial categories."
      ],
      "metadata": {
        "id": "zYtI7TCRNtlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = df.head(500).copy() # Using 500 jobs to analyze scores\n",
        "job_texts = sample_df['combined_text'].astype(str).tolist()\n",
        "\n",
        "print(\"\\nEncoding job descriptions into vectors\")\n",
        "job_embeddings = model.encode(job_texts, convert_to_tensor=True, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nCalculating similarity scores\")\n",
        "cosine_scores = util.pytorch_cos_sim(job_embeddings, category_embeddings)\n",
        "\n",
        "# Find the best match (highest score) for each job\n",
        "top_scores, top_indices = torch.max(cosine_scores, dim=1)"
      ],
      "metadata": {
        "id": "FdjVIM6Y69EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df['sub_category'] = [all_sub_categories[i] for i in top_indices]\n",
        "sample_df['main_category'] = sample_df['sub_category'].map(sub_to_main_map)\n",
        "sample_df['confidence_score'] = top_scores.cpu().numpy()\n",
        "\n",
        "print(\"Classification and scoring complete.\")"
      ],
      "metadata": {
        "id": "qTNxl0dE6-aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Classification Finished! ---\")\n",
        "final_classification_df = sample_df[[\n",
        "    'job_id',\n",
        "    'title',\n",
        "    'main_category',\n",
        "    'sub_category',\n",
        "    'confidence_score'\n",
        "]].copy()\n",
        "\n",
        "final_classification_df.head(50)"
      ],
      "metadata": {
        "id": "ZX_eIUV97C3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_classification_df[50:101]"
      ],
      "metadata": {
        "id": "r89Q1KJ17XCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_classification_df[102:150]"
      ],
      "metadata": {
        "id": "xyj5a7X27luy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "try 2 : trying with specific threshold scores per topic"
      ],
      "metadata": {
        "id": "id1oMUhSPcaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Define Custom Confidence Thresholds per Category"
      ],
      "metadata": {
        "id": "MV0LW7gYOFRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "categories_threshold defined by self"
      ],
      "metadata": {
        "id": "EBoRq7NSONfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_thresholds = {\n",
        "    'Technology': 0.30,\n",
        "    'Finance': 0.35,\n",
        "    'Legal': 0.35,\n",
        "    'Healthcare (Research & Admin)': 0.38,\n",
        "    'Marketing': 0.35,\n",
        "    'Human Resources': 0.40,\n",
        "    'Education & EdTech': 0.30,\n",
        "    'Consulting & Strategy': 0.35,\n",
        "    'Supply Chain & Logistics': 0.45,\n",
        "    'Design': 0.35,\n",
        "    'Automotive': 0.15,\n",
        "    'Media & Journalism': 0.10\n",
        "}\n",
        "print(\"Custom category-specific thresholds are set.\")"
      ],
      "metadata": {
        "id": "kZ3XDZqiQe2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Full Classification on Entire Dataset"
      ],
      "metadata": {
        "id": "BSGzWG8bOS6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat encoding and classification procedure on the full dataset."
      ],
      "metadata": {
        "id": "Xv3DtT_7OVbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_df = df.head(500).copy()\n",
        "# For now, we'll use a sample to see the results of the thresholding\n",
        "\n",
        "# Using the full dataframe now\n",
        "sample_df = df.copy()\n",
        "\n",
        "job_texts = sample_df['combined_text'].astype(str).tolist()\n",
        "\n",
        "print(\"\\nEncoding job descriptions into vectors\")\n",
        "job_embeddings = model.encode(job_texts, convert_to_tensor=True, show_progress_bar=True)\n",
        "\n",
        "print(\"\\nCalculating similarity scores\")\n",
        "cosine_scores = util.pytorch_cos_sim(job_embeddings, category_embeddings)\n",
        "top_scores, top_indices = torch.max(cosine_scores, dim=1)"
      ],
      "metadata": {
        "id": "RH8ZPpZrQmy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df['sub_category'] = [all_sub_categories[i] for i in top_indices]\n",
        "sample_df['main_category'] = sample_df['sub_category'].map(sub_to_main_map)\n",
        "sample_df['confidence_score'] = top_scores.cpu().numpy()\n",
        "print(\"Initial classification and scoring complete.\")"
      ],
      "metadata": {
        "id": "yFnYricaQsBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Apply Category-Specific Confidence Thresholds on complete dataset"
      ],
      "metadata": {
        "id": "FyfXabsUOlTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mark jobs as 'Other' if their confidence score is below the category-specific thresholds."
      ],
      "metadata": {
        "id": "s2Qp3hc7OphN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nApplying custom thresholds to filter results...\")\n",
        "\n",
        "def apply_threshold(row):\n",
        "    main_cat = row['main_category']\n",
        "    score = row['confidence_score']\n",
        "\n",
        "    threshold = category_thresholds.get(main_cat, 0.5)\n",
        "\n",
        "    if score < threshold:\n",
        "        return 'Other'\n",
        "    else:\n",
        "        return main_cat"
      ],
      "metadata": {
        "id": "STaf5tRfTc7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df['final_main_category'] = sample_df.apply(apply_threshold, axis=1)\n",
        "\n",
        "sample_df['final_sub_category'] = sample_df.apply(\n",
        "    lambda row: row['sub_category'] if row['final_main_category'] != 'Other' else 'Other',\n",
        "    axis=1\n",
        ")\n",
        "print(\"Thresholding complete.\")"
      ],
      "metadata": {
        "id": "Z0qsY2kxTfop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Prepare Final Classified DataFrame and Save"
      ],
      "metadata": {
        "id": "dOl0q8bAO6Eh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format final DataFrame to include relevant columns and save to CSV on Google Drive."
      ],
      "metadata": {
        "id": "oHh0MEVjO9p5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Final Classification Finished! ---\")\n",
        "final_df = sample_df[[\n",
        "    'job_id',\n",
        "    'title',\n",
        "    'final_main_category',\n",
        "    'final_sub_category',\n",
        "    'confidence_score'\n",
        "]].copy()\n",
        "\n",
        "final_df.rename(columns={\n",
        "    'final_main_category': 'main_category',\n",
        "    'final_sub_category': 'sub_category'\n",
        "}, inplace=True)\n",
        "\n",
        "final_df.head(50)"
      ],
      "metadata": {
        "id": "DzkWRH3uO3-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows, num_columns = final_df.shape\n",
        "\n",
        "print(f\"The final DataFrame has:\")\n",
        "print(f\"- {num_rows} rows\")\n",
        "print(f\"- {num_columns} columns\")"
      ],
      "metadata": {
        "id": "Xu69HXtzWQLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/drive/My Drive/job-analysis/job-analysis-dataset/classified_jobs/classified_jobs.csv'\n",
        "\n",
        "print(f\"Saving the final classified DataFrame to: {output_path}\")\n",
        "final_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"\\nFile saved successfully!\")"
      ],
      "metadata": {
        "id": "v7FvRXlcVlQl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}